\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{american}{}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{ii}{dummy.2}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{iii}{dummy.4}}
\citation{li2013spoken}
\citation{zhao2008cortical}
\citation{ramus1999language}
\citation{zhao2008cortical}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter1}{{1}{1}{Introduction}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Speech Recognition}{1}{section.7}}
\citation{li2013spoken}
\citation{ramus1999language,navratil2001spoken}
\citation{li2013spoken}
\citation{rabiner1993yegnanarayana,hermansky1990perceptual,torres2002approaches}
\citation{wong2002methods,zissman1996comparison,zissman1993automatic,sugiyama1991automatic,braun1998automatic,richardson2015deep}
\citation{jurafsky2000speech}
\citation{li2013spoken}
\citation{richardson2015deep,gonzalez2014automatic,lopez2014automatic,lopez2016use,garcia2016stacked,snyder2018spoken,sarma2018language}
\citation{richardson2015deep}
\citation{richardson2015deep}
\citation{snyder2018spoken,sarma2018language}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Language identification, Language verification and Language diarization}{3}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Language identification and verification}{3}{subsection.9}}
\citation{lyu2013language}
\citation{lyu2013language}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Basic block diagram of language identification/verification system.\relax }}{4}{figure.caption.10}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{lr}{{1.1}{4}{Basic block diagram of language identification/verification system.\relax }{figure.caption.10}{}}
\citation{lyu2013language1}
\citation{lyu2013language1}
\citation{lyu2013language}
\citation{yilmaz2017language}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Language diarization}{5}{subsection.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Basic block diagram of language diarization system~\cite  {lyu2013language1}.\relax }}{5}{figure.caption.12}}
\newlabel{ld}{{1.2}{5}{Basic block diagram of language diarization system~\cite {lyu2013language1}.\relax }{figure.caption.12}{}}
\citation{leonard1974automatic}
\citation{house1977toward}
\citation{li1980statistical}
\citation{cimarusti1982development}
\citation{foil1986language}
\citation{goodman1989improved}
\citation{sugiyama1991automatic}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Major milestones for language recognition}{6}{section.13}}
\citation{nakagawa1992speaker}
\citation{zissman1993automatic}
\citation{muthusamy1992ogi}
\citation{zissman1996comparison}
\citation{wong2002methods}
\citation{reynolds2000speaker}
\citation{torres2002approaches}
\citation{li2007vector}
\citation{ma2007spoken}
\citation{dehak2011language}
\citation{song2013vector}
\citation{gonzalez2014automatic}
\citation{lei2014application}
\citation{richardson2015deep}
\citation{zhang2018language}
\citation{snyder2018spoken}
\citation{leonard1974automatic}
\citation{house1977toward}
\citation{li1980statistical}
\citation{cimarusti1982development}
\citation{foil1986language}
\citation{goodman1989improved}
\citation{sugiyama1991automatic}
\citation{nakagawa1992speaker}
\citation{zissman1993automatic}
\citation{zissman1996comparison}
\citation{wong2002methods}
\citation{torres2002approaches}
\citation{li2007vector}
\citation{ma2007spoken}
\citation{dehak2011language}
\citation{song2013vector}
\citation{gonzalez2014automatic}
\citation{lei2014application}
\citation{richardson2015deep}
\citation{zhang2018language}
\citation{snyder2018spoken}
\citation{li2013spoken}
\citation{muthusamy1992ogi}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Databases for spoken language recognition}{10}{section.16}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces A summary on different studies made on language recognition.\relax }}{11}{table.caption.14}}
\newlabel{tab_review}{{1.1}{11}{A summary on different studies made on language recognition.\relax }{table.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.2}{\ignorespaces A summary on different studies made on language recognition.\relax }}{12}{table.caption.15}}
\newlabel{tab_review2}{{1.2}{12}{A summary on different studies made on language recognition.\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Oregon graduate institute telephone speech corpus (OGI-TS)}{12}{subsection.17}}
\citation{lander1995ogi}
\citation{ambikairajah2011language,li2013spoken}
\citation{martin2003nist,martin2009,greenberg20122011}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.4.1.1}OGI-TS 22 language corpus}{13}{subsubsection.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}LDC callfriend telephone speech corpus}{13}{subsection.19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}NIST Language recognition corpus (NIST LRE)}{13}{subsection.20}}
\citation{li2013spoken}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Performance measure for language recognition}{14}{section.24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Average detection cost($C_{avg}$)}{14}{subsection.25}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Summery and Discussion}{15}{section.26}}
\citation{ambikairajah2011language}
\citation{chakroborty2009improved}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Acoustic feature extraction and classification techniques used for Spoken language recognition}{16}{chapter.27}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Mel frequency cepstral coefficients (MFCC)}{16}{section.28}}
\citation{beigi2011speaker}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Block diagram of MFCC extraction.\relax }}{17}{figure.caption.29}}
\newlabel{mfcc}{{2.1}{17}{Block diagram of MFCC extraction.\relax }{figure.caption.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Pre-emphasis}{17}{subsection.30}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The power spectral density of the original speech signal and pre-emphasized speech signal sampled at 8000 Hz.\relax }}{17}{figure.caption.31}}
\newlabel{pemp}{{2.2}{17}{The power spectral density of the original speech signal and pre-emphasized speech signal sampled at 8000 Hz.\relax }{figure.caption.31}{}}
\citation{beigi2011speaker}
\newlabel{pr}{{2.1}{18}{Pre-emphasis}{equation.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Frame blocking}{18}{subsection.33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Windowing}{18}{subsection.34}}
\citation{beigi2011speaker}
\citation{chakroborty2009improved}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}DFT}{19}{subsection.37}}
\newlabel{dft}{{2.4}{19}{DFT}{equation.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Power spectrum}{19}{subsection.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}Mel filter warping}{19}{subsection.40}}
\newlabel{hz2mel}{{2.5}{19}{Mel filter warping}{equation.42}{}}
\newlabel{Mel2hz}{{2.6}{19}{Mel filter warping}{equation.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Shape of Mel filter bank for a 24 filter system with sampling frequency of 8000 Hz .\relax }}{20}{figure.caption.41}}
\newlabel{Mel}{{2.3}{20}{Shape of Mel filter bank for a 24 filter system with sampling frequency of 8000 Hz .\relax }{figure.caption.41}{}}
\newlabel{trf}{{2.7}{20}{Mel filter warping}{equation.44}{}}
\newlabel{sMel}{{2.8}{20}{Mel filter warping}{equation.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.7}log(.)}{20}{subsection.46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.8}Inverse DCT}{20}{subsection.47}}
\citation{ambikairajah2011language}
\newlabel{dct}{{2.9}{21}{Inverse DCT}{equation.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Delta and Delta-Delta cepstra ($\Delta $ and $\Delta -\Delta $)}{21}{section.49}}
\newlabel{del}{{2.10}{21}{Delta and Delta-Delta cepstra ($\Delta $ and $\Delta -\Delta $)}{equation.50}{}}
\newlabel{start}{{2.11}{21}{Delta and Delta-Delta cepstra ($\Delta $ and $\Delta -\Delta $)}{equation.51}{}}
\newlabel{end}{{2.12}{21}{Delta and Delta-Delta cepstra ($\Delta $ and $\Delta -\Delta $)}{equation.52}{}}
\citation{torres2002approaches}
\citation{ambikairajah2011language}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Shifted delta coefficients (SDC)}{22}{section.53}}
\newlabel{sdc1}{{2.13}{22}{Shifted delta coefficients (SDC)}{equation.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces SDC feature extraction at $n^{th}$ frame, $z-d-p-k=7-1-3-7$.\relax }}{23}{figure.caption.54}}
\newlabel{sdc}{{2.4}{23}{SDC feature extraction at $n^{th}$ frame, $z-d-p-k=7-1-3-7$.\relax }{figure.caption.54}{}}
\newlabel{sdc2}{{2.14}{23}{Shifted delta coefficients (SDC)}{equation.56}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Gaussian Mixture Model}{23}{section.57}}
\newlabel{gmm_sc}{{2.4}{23}{Gaussian Mixture Model}{section.57}{}}
\citation{reynolds1995speaker}
\citation{reynolds1995speaker}
\newlabel{pr}{{2.15}{24}{Gaussian Mixture Model}{equation.58}{}}
\newlabel{nor}{{2.16}{24}{Gaussian Mixture Model}{equation.59}{}}
\newlabel{con}{{2.17}{24}{Gaussian Mixture Model}{equation.60}{}}
\newlabel{gus}{{2.18}{24}{Gaussian Mixture Model}{equation.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Training of GMMs}{25}{subsection.62}}
\newlabel{llk}{{2.19}{25}{Training of GMMs}{equation.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Basic block diagram of GMM training.\relax }}{25}{figure.caption.64}}
\newlabel{gem}{{2.5}{25}{Basic block diagram of GMM training.\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.1}Expectation Maximization Algorithm}{26}{subsubsection.65}}
\newlabel{lpd}{{2.20}{26}{Expectation Maximization Algorithm}{equation.66}{}}
\newlabel{gm}{{2.21}{26}{Expectation Maximization Algorithm}{equation.67}{}}
\newlabel{opmv}{{2.22}{26}{Expectation Maximization Algorithm}{equation.68}{}}
\newlabel{obj}{{2.23}{26}{Expectation Maximization Algorithm}{equation.69}{}}
\newlabel{wop}{{2.24}{26}{Expectation Maximization Algorithm}{equation.70}{}}
\newlabel{lsl}{{2.25}{27}{Expectation Maximization Algorithm}{equation.71}{}}
\newlabel{op}{{2.27}{27}{Expectation Maximization Algorithm}{equation.73}{}}
\citation{reynolds2000speaker}
\newlabel{opi}{{2.28}{28}{Expectation Maximization Algorithm}{equation.74}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.2}Maximum a posteriori (MAP) Parameter estimation}{28}{subsubsection.75}}
\newlabel{secmap}{{2.4.1.2}{28}{Maximum a posteriori (MAP) Parameter estimation}{subsubsection.75}{}}
\citation{reynolds1995speaker}
\citation{reynolds1995speaker}
\newlabel{s1map}{{2.29}{29}{Maximum a posteriori (MAP) Parameter estimation}{equation.78}{}}
\newlabel{s2map}{{2.30}{29}{Maximum a posteriori (MAP) Parameter estimation}{equation.79}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces (a) The training vectors (x\IeC {\textquoteright }s) are probabilistically mapped into the UBM (prior) mixtures. (b) The adapted mixture parameters are derived using the statistics of the new data and the UBM (prior) mixture parameters. The adaptation is data dependent, so UBM (prior) mixture parameters are adapted by different amounts~\cite  {reynolds1995speaker}.\relax }}{30}{figure.caption.81}}
\newlabel{map}{{2.6}{30}{(a) The training vectors (x’s) are probabilistically mapped into the UBM (prior) mixtures. (b) The adapted mixture parameters are derived using the statistics of the new data and the UBM (prior) mixture parameters. The adaptation is data dependent, so UBM (prior) mixture parameters are adapted by different amounts~\cite {reynolds1995speaker}.\relax }{figure.caption.81}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Basic block diagram of language identification using GMM.\relax }}{30}{figure.caption.83}}
\newlabel{gmm}{{2.7}{30}{Basic block diagram of language identification using GMM.\relax }{figure.caption.83}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Testing of GMMs}{30}{subsection.82}}
\newlabel{tllk}{{2.32}{30}{Testing of GMMs}{equation.84}{}}
\citation{ambikairajah2011language}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Gaussian Mixture Model and Universal Background Model (GMM-UBM)}{31}{section.86}}
\newlabel{cgmmubm}{{2.5}{31}{Gaussian Mixture Model and Universal Background Model (GMM-UBM)}{section.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Basic block diagram of language identification using GMM-UBM.\relax }}{31}{figure.caption.87}}
\newlabel{ubm}{{2.8}{31}{Basic block diagram of language identification using GMM-UBM.\relax }{figure.caption.87}{}}
\citation{kenny2005joint}
\citation{dehak2011front}
\newlabel{gmmubmeva}{{2.34}{32}{Gaussian Mixture Model and Universal Background Model (GMM-UBM)}{equation.88}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}I-vector based language identification system}{32}{section.89}}
\newlabel{ivector}{{2.6}{32}{I-vector based language identification system}{section.89}{}}
\newlabel{jfa}{{2.35}{32}{I-vector based language identification system}{equation.90}{}}
\newlabel{ivec}{{2.36}{33}{I-vector based language identification system}{equation.91}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Basic block diagram of language identification using i-vector.\relax }}{33}{figure.caption.92}}
\newlabel{i-vec}{{2.9}{33}{Basic block diagram of language identification using i-vector.\relax }{figure.caption.92}{}}
\citation{kenny2005joint}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}T Matrix training}{35}{subsection.96}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}I-vector estimation}{35}{subsection.106}}
\newlabel{eivec}{{2.43}{35}{I-vector estimation}{equation.107}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Cosine kernel scoring}{36}{subsection.108}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Intersession compensation techniques}{36}{subsection.110}}
\newlabel{lda}{{2.6.4}{36}{Intersession compensation techniques}{subsection.110}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.1}Linear discriminant analysis (LDA)}{36}{subsubsection.111}}
\newlabel{ld1}{{2.45}{36}{Linear discriminant analysis (LDA)}{equation.112}{}}
\citation{hatch2006within}
\citation{hatch2006within}
\citation{campbell2006svm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.2}Within class covariance normalization (WCCN)}{37}{subsubsection.116}}
\citation{lopez2016use}
\citation{lopez2016use}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.3}Nuisance attribute projection (NAP)}{38}{subsubsection.121}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Feedforward network based model}{38}{section.125}}
\newlabel{ffnn}{{2.7}{38}{Feedforward network based model}{section.125}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Feedforward network based classifier~\cite  {lopez2016use}.\relax }}{38}{figure.caption.126}}
\newlabel{ffn}{{2.10}{38}{Feedforward network based classifier~\cite {lopez2016use}.\relax }{figure.caption.126}{}}
\citation{zhang2018language}
\citation{zhang2018language}
\citation{jiang2014deep}
\citation{jiang2014deep}
\citation{waibel1989phonemetdnn}
\citation{snyder2018spoken}
\citation{snyder2018spoken}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Bottleneck feature I-vector model}{39}{section.128}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Bottleneck feature extraction~\cite  {zhang2018language}.\relax }}{39}{figure.caption.129}}
\newlabel{bnf}{{2.11}{39}{Bottleneck feature extraction~\cite {zhang2018language}.\relax }{figure.caption.129}{}}
\citation{snyder2018spoken}
\citation{snyder2018spoken}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Bottleneck feature-I-vector based language identification system~\cite  {jiang2014deep}.\relax }}{40}{figure.caption.130}}
\newlabel{bnf1}{{2.12}{40}{Bottleneck feature-I-vector based language identification system~\cite {jiang2014deep}.\relax }{figure.caption.130}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}X-vector based modeling}{40}{section.131}}
\newlabel{xvector}{{2.9}{40}{X-vector based modeling}{section.131}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces  Computation in TDNN with sub-sampling (red) and without sub-sampling (blue+red)~\cite  {snyder2018spoken}.\relax }}{40}{figure.caption.132}}
\newlabel{tdnn}{{2.13}{40}{Computation in TDNN with sub-sampling (red) and without sub-sampling (blue+red)~\cite {snyder2018spoken}.\relax }{figure.caption.132}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The embedding DNN architecture~\cite  {snyder2018spoken}.\relax }}{41}{table.caption.133}}
\newlabel{xvac_ar}{{2.1}{41}{The embedding DNN architecture~\cite {snyder2018spoken}.\relax }{table.caption.133}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Delivered System Description }{42}{chapter.134}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter1}{{3}{42}{Delivered System Description}{chapter.134}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Database Description}{42}{section.135}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Speech data available in each language\relax }}{42}{table.caption.136}}
\newlabel{Data_amount}{{3.1}{42}{Speech data available in each language\relax }{table.caption.136}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}System Description}{42}{section.137}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}GMM Based System}{42}{subsection.138}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces GMM based system performance\relax }}{43}{table.caption.139}}
\newlabel{gmm_sys}{{3.2}{43}{GMM based system performance\relax }{table.caption.139}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}GMM-UBM Based System}{43}{subsection.140}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces GMM UBM based system performance\relax }}{43}{table.caption.141}}
\newlabel{gmm_ubm_sys}{{3.3}{43}{GMM UBM based system performance\relax }{table.caption.141}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}I-vector based System}{43}{subsection.142}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces I-vector based system performance\relax }}{43}{table.caption.143}}
\newlabel{ivector_sys}{{3.4}{43}{I-vector based system performance\relax }{table.caption.143}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Feedforward Network Based System}{44}{subsection.144}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Feedforward neural network based system performance\relax }}{44}{table.caption.145}}
\newlabel{ffnn_sys}{{3.5}{44}{Feedforward neural network based system performance\relax }{table.caption.145}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}X-vector Based System}{44}{subsection.146}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces X-vector based system performance\relax }}{44}{table.caption.147}}
\newlabel{xvector_sys}{{3.6}{44}{X-vector based system performance\relax }{table.caption.147}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Summary and Discussion}{44}{section.148}}
\bibstyle{Bibliography/IEEEtran}
\bibdata{Bibliography/Bibliography.bib}
